{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e01a0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "PGN_DIR = \"/root/sf_pgns\"\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"official-stockfish/fishtest_pgns\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=\"25-01-1*/*/*.pgn.gz\", \n",
    "    local_dir=PGN_DIR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27a3b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import math\n",
    "from typing import Optional, Tuple, Iterator, List\n",
    "\n",
    "import numpy as np\n",
    "import chess\n",
    "import chess.pgn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CONSTANTS\n",
    "# =========================================================\n",
    "\n",
    "# Example Stockfish comments stored in node.comment:\n",
    "#   \"+1.20/26 3.2s\"\n",
    "#   \"-1.18/26 2.8s\"\n",
    "#   \"0.00/65 3.126s, Draw by adjudication\"\n",
    "#   \"+M5/25 0.1s\"\n",
    "#\n",
    "# We capture:\n",
    "#   group(1): eval token (e.g. \"-0.89\" or \"+M5\" or \"0.00\")\n",
    "#   group(2): depth        (e.g. \"29\")\n",
    "#   group(3): time_s       (e.g. \"23.772\")\n",
    "#\n",
    "\n",
    "EVAL_RE = re.compile(\n",
    "    r\"([+#-]?(?:\\d+(?:\\.\\d+)?|M\\d+))/(\\d+)\\s+([0-9.]+)s\"\n",
    ")\n",
    "\n",
    "# How aggressively to squash pawn evals into [-1, 1]\n",
    "# value_normalized = clip(eval_pawns, [-VALUE_SCALE, VALUE_SCALE]) / VALUE_SCALE\n",
    "VALUE_SCALE = 4.0  # 4 pawns = Â±1.0; tune if needed\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# BOARD ENCODING: 18 PLANES\n",
    "# =========================================================\n",
    "\n",
    "def board_to_matrix(board: chess.Board) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a chess.Board to an 18x8x8 binary tensor.\n",
    "\n",
    "    Planes 0-11: Piece planes\n",
    "      0: White pawns     6: Black pawns\n",
    "      1: White knights   7: Black knights\n",
    "      2: White bishops   8: Black bishops\n",
    "      3: White rooks     9: Black rooks\n",
    "      4: White queens   10: Black queens\n",
    "      5: White kings    11: Black kings\n",
    "\n",
    "    Plane 12: Side to move (1 for white, 0 for black)\n",
    "    Planes 13-16: Castling rights\n",
    "      13: White kingside\n",
    "      14: White queenside\n",
    "      15: Black kingside\n",
    "      16: Black queenside\n",
    "\n",
    "    Plane 17: En passant target square (if any)\n",
    "    \"\"\"\n",
    "    mat = np.zeros((18, 8, 8), dtype=np.float32)\n",
    "\n",
    "    piece_mapping = {\n",
    "        chess.PAWN:   0,\n",
    "        chess.KNIGHT: 1,\n",
    "        chess.BISHOP: 2,\n",
    "        chess.ROOK:   3,\n",
    "        chess.QUEEN:  4,\n",
    "        chess.KING:   5,\n",
    "    }\n",
    "\n",
    "    for square, piece in board.piece_map().items():\n",
    "        plane = piece_mapping[piece.piece_type]\n",
    "        if piece.color == chess.BLACK:\n",
    "            plane += 6\n",
    "        row, col = divmod(square, 8)\n",
    "        mat[plane, row, col] = 1.0\n",
    "\n",
    "    # Side to move\n",
    "    mat[12] = 1.0 if board.turn == chess.WHITE else 0.0\n",
    "\n",
    "    # Castling rights\n",
    "    mat[13] = 1.0 if board.has_kingside_castling_rights(chess.WHITE) else 0.0\n",
    "    mat[14] = 1.0 if board.has_queenside_castling_rights(chess.WHITE) else 0.0\n",
    "    mat[15] = 1.0 if board.has_kingside_castling_rights(chess.BLACK) else 0.0\n",
    "    mat[16] = 1.0 if board.has_queenside_castling_rights(chess.BLACK) else 0.0\n",
    "\n",
    "    # En passant square\n",
    "    if board.ep_square is not None:\n",
    "        ep_row, ep_col = divmod(board.ep_square, 8)\n",
    "        mat[17, ep_row, ep_col] = 1.0\n",
    "\n",
    "    return mat\n",
    "\n",
    "\n",
    "def move_to_index(move: chess.Move) -> int:\n",
    "    \"\"\"\n",
    "    Encode a move as an integer in range [0, 4096):\n",
    "        from_square * 64 + to_square\n",
    "    \"\"\"\n",
    "    return move.from_square * 64 + move.to_square\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# EVAL PARSING (RAW PAWNS)\n",
    "# =========================================================\n",
    "\n",
    "def parse_stockfish_eval(comment: str) -> Tuple[Optional[float], Optional[int], Optional[float], Optional[bool]]:\n",
    "    \"\"\"\n",
    "    Parse a Stockfish comment like:\n",
    "      '-0.23/19 2.7s'\n",
    "      '+M5/25 0.1s'\n",
    "      '0.00/65 3.126s, Draw by adjudication'\n",
    "\n",
    "    Returns:\n",
    "      score_pawns : score in pawns from the POV of the *player who just moved* (mover),\n",
    "                    positive means advantage for mover. None if not found.\n",
    "      depth       : search depth (int) or None\n",
    "      time_s      : search time in seconds (float) or None\n",
    "      is_mate     : True if mate score, False otherwise, None if no eval.\n",
    "    \"\"\"\n",
    "    if not comment:\n",
    "        return None, None, None, None\n",
    "\n",
    "    m = EVAL_RE.search(comment)\n",
    "    if not m:\n",
    "        return None, None, None, None\n",
    "\n",
    "    token  = m.group(1)   # \"-0.23\" or \"+M5\" or \"0.00\"\n",
    "    depth  = int(m.group(2))\n",
    "    time_s = float(m.group(3))\n",
    "\n",
    "    # Mate token?\n",
    "    if \"M\" in token:\n",
    "        mate_m = re.match(r\"([+-]?)M(\\d+)\", token)\n",
    "        if not mate_m:\n",
    "            return None, None, None, None\n",
    "        sign = -1 if mate_m.group(1) == \"-\" else 1\n",
    "        # Use a large pawn magnitude (e.g. 100 pawns)\n",
    "        score_pawns = sign * 100.0\n",
    "        is_mate = True\n",
    "        return score_pawns, depth, time_s, is_mate\n",
    "\n",
    "    # Normal score (pawns in the PGN)\n",
    "    try:\n",
    "        score_pawns = float(token)\n",
    "    except ValueError:\n",
    "        return None, None, None, None\n",
    "\n",
    "    is_mate = False\n",
    "    return score_pawns, depth, time_s, is_mate\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# VALUE NORMALIZATION (LINEAR, NO TANH)\n",
    "# =========================================================\n",
    "\n",
    "def normalize_eval_pawns(eval_pawns: float, scale: float = VALUE_SCALE) -> float:\n",
    "    \"\"\"\n",
    "    Map a pawn eval (from POV of side to move) to [-1, +1]\n",
    "    using simple linear scaling with clipping:\n",
    "\n",
    "        clipped = clip(eval_pawns, -scale, +scale)\n",
    "        v_norm  = clipped / scale\n",
    "\n",
    "    Example (scale=4.0):\n",
    "        eval_pawns = +1.0  -> +0.25\n",
    "        eval_pawns = -2.0  -> -0.50\n",
    "        eval_pawns = +10.0 -> +1.00 (saturated)\n",
    "    \"\"\"\n",
    "    clipped = max(-scale, min(scale, eval_pawns))\n",
    "    return clipped / scale\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# PGN PARSING (.pgn.gz, fishtest format)\n",
    "# =========================================================\n",
    "\n",
    "def parse_pgn_gz(\n",
    "    filepath: str,\n",
    "    max_games: Optional[int] = None,\n",
    "    min_depth: int = 18,\n",
    ") -> Iterator[Tuple[np.ndarray, np.ndarray, float]]:\n",
    "    \"\"\"\n",
    "    Parse a gzip-compressed fishtest PGN file and yield training samples.\n",
    "\n",
    "    For each *interior* position (not the final move of the game):\n",
    "\n",
    "      - Input X      : board AFTER a move has been played.\n",
    "      - y_policy     : next mainline move from that position (one-hot over 4096).\n",
    "      - y_value_norm : **linearly normalized** eval in [-1, +1]\n",
    "                       from POV of the side to move.\n",
    "\n",
    "    Example snippet:\n",
    "        e4 {+1.08/21 5.8s} e5 {-0.52/18 2.6s} 2. Be2 {+1.19/17 ...}\n",
    "\n",
    "    In python-chess, node.comment holds just the inner text, e.g. \"+1.08/21 5.8s\".\n",
    "\n",
    "    We emit:\n",
    "      Row 1:\n",
    "        X            = position after e4 (Black to move)\n",
    "        raw_pawns    = -1.08   (flip because comment is from White/mover POV)\n",
    "        y_value_norm = normalize_eval_pawns(raw_pawns, VALUE_SCALE)\n",
    "        y_policy     = e5\n",
    "\n",
    "      Row 2:\n",
    "        X            = position after e5 (White to move)\n",
    "        raw_pawns    = +0.52   (flip -0.52 from Black POV -> White POV)\n",
    "        y_value_norm = normalize_eval_pawns(raw_pawns, VALUE_SCALE)\n",
    "        y_policy     = Be2\n",
    "    \"\"\"\n",
    "    with gzip.open(filepath, mode=\"rt\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        game_counter = 0\n",
    "\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            game_counter += 1\n",
    "            if max_games is not None and game_counter > max_games:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            node = game  # root node\n",
    "\n",
    "            while node.variations:\n",
    "                next_node = node.variation(0)\n",
    "                move = next_node.move\n",
    "\n",
    "                # Play the move; this is the position we want as input X\n",
    "                board.push(move)\n",
    "\n",
    "                # Parse engine eval on this move's comment\n",
    "                raw_comment = next_node.comment or \"\"\n",
    "                score_pawns, depth, time_s, is_mate = parse_stockfish_eval(raw_comment)\n",
    "\n",
    "                # --- DEBUG: show first few comments for the first game ---\n",
    "                if game_counter == 1:\n",
    "                    if not hasattr(parse_pgn_gz, \"_debug_shown\"):\n",
    "                        parse_pgn_gz._debug_shown = 0\n",
    "                    if parse_pgn_gz._debug_shown < 10:\n",
    "                        print(\"\\n[DEBUG] Comment:\", repr(raw_comment))\n",
    "                        print(\"[DEBUG] Parsed eval:\", score_pawns, \"depth:\", depth, \"time:\", time_s, \"mate:\", is_mate)\n",
    "                        print(\"[DEBUG] Board FEN after move:\", board.fen())\n",
    "                        parse_pgn_gz._debug_shown += 1\n",
    "                # -----------------------------------------------------------\n",
    "\n",
    "                # If no eval or too shallow, skip this position\n",
    "                if score_pawns is None or depth is None or depth < min_depth:\n",
    "                    node = next_node\n",
    "                    continue\n",
    "\n",
    "                # score_pawns is from POV of the player who just moved.\n",
    "                # In the resulting position, it's the *other* side to move.\n",
    "                # We want eval from POV of the side to move => flip sign.\n",
    "                y_value_pawns = -score_pawns\n",
    "\n",
    "                # Linearly normalize pawn eval -> [-1, +1]\n",
    "                y_value_norm = normalize_eval_pawns(y_value_pawns, VALUE_SCALE)\n",
    "\n",
    "                # Policy target is the *next* mainline move if it exists\n",
    "                if not next_node.variations:\n",
    "                    # No next move from this position => no policy label; skip\n",
    "                    node = next_node\n",
    "                    continue\n",
    "\n",
    "                next_move_node = next_node.variation(0)\n",
    "                policy_move = next_move_node.move\n",
    "                move_idx = move_to_index(policy_move)\n",
    "\n",
    "                y_policy = np.zeros(4096, dtype=np.float32)\n",
    "                y_policy[move_idx] = 1.0\n",
    "\n",
    "                # Encode board AFTER 'move'\n",
    "                X = board_to_matrix(board)\n",
    "\n",
    "                # NOTE: we yield the **normalized** value\n",
    "                yield X, y_policy, float(y_value_norm)\n",
    "\n",
    "                # Advance the traversal\n",
    "                node = next_node\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# BATCH SAVING\n",
    "# =========================================================\n",
    "\n",
    "def save_batch(\n",
    "    X_list: List[np.ndarray],\n",
    "    y_list_pol: List[np.ndarray],\n",
    "    y_list_val: List[float],\n",
    "    output_dir: str,\n",
    "    batch_num: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save a batch of data to disk as three .npy files:\n",
    "\n",
    "      X_boards_batch_XXXX.npy : (B, 18, 8, 8)\n",
    "      y_policy_batch_XXXX.npy : (B, 4096)\n",
    "      y_value_batch_XXXX.npy  : (B,)  -- **normalized** evals in [-1, +1]\n",
    "                                      from POV of side to move\n",
    "    \"\"\"\n",
    "    X_arr     = np.stack(X_list, axis=0).astype(np.float32)\n",
    "    y_arr_pol = np.stack(y_list_pol, axis=0).astype(np.float32)\n",
    "    y_arr_val = np.array(y_list_val, dtype=np.float32)\n",
    "\n",
    "    x_filename     = os.path.join(output_dir, f\"X_boards_batch_{batch_num:04d}.npy\")\n",
    "    y_pol_filename = os.path.join(output_dir, f\"y_policy_batch_{batch_num:04d}.npy\")\n",
    "    y_val_filename = os.path.join(output_dir, f\"y_value_batch_{batch_num:04d}.npy\")\n",
    "\n",
    "    np.save(x_filename,     X_arr)\n",
    "    np.save(y_pol_filename, y_arr_pol)\n",
    "    np.save(y_val_filename, y_arr_val)\n",
    "\n",
    "    x_size     = os.path.getsize(x_filename)     / (1024**2)\n",
    "    y_pol_size = os.path.getsize(y_pol_filename) / (1024**2)\n",
    "    y_val_size = os.path.getsize(y_val_filename) / (1024**2)\n",
    "\n",
    "    print(\n",
    "        f\"    Batch {batch_num:04d}: {len(X_list):,} samples \"\n",
    "        f\"({x_size:.1f}MB + {y_pol_size:.1f}MB + {y_val_size:.1f}MB)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# PGN FILE DISCOVERY\n",
    "# =========================================================\n",
    "\n",
    "def collect_pgn_gz_files(root_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Recursively collect all .pgn.gz files under root_dir.\n",
    "    \"\"\"\n",
    "    paths: List[str] = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith(\".pgn.gz\"):\n",
    "                paths.append(os.path.join(dirpath, fname))\n",
    "    paths.sort()\n",
    "    return paths\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# TOP-LEVEL DRIVER\n",
    "# =========================================================\n",
    "\n",
    "def process_all_pgns(\n",
    "    pgn_root: str,\n",
    "    output_dir: str,\n",
    "    max_positions: Optional[int] = None,\n",
    "    batch_size: int = 10_000,\n",
    "    max_games_per_file: Optional[int] = None,\n",
    "    min_depth: int = 18,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process all .pgn.gz files under pgn_root and save in batches.\n",
    "\n",
    "    Each emitted row satisfies:\n",
    "      - X encodes the position AFTER a move (side to move = board.turn).\n",
    "      - y_policy is the next mainline move from that position.\n",
    "      - y_value is the **linearly normalized** engine eval (in [-1, +1])\n",
    "        from POV of side to move.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    pgn_files = collect_pgn_gz_files(pgn_root)\n",
    "\n",
    "    print(f\"Starting processing of {len(pgn_files)} PGN files under {pgn_root}\")\n",
    "    print(f\"Batch size: {batch_size:,} positions per batch\")\n",
    "    if max_positions is not None:\n",
    "        print(f\"Global position cap: {max_positions:,}\")\n",
    "    if max_games_per_file is not None:\n",
    "        print(f\"Per-file game cap: {max_games_per_file}\")\n",
    "    print(f\"Min eval depth: {min_depth}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"VALUE_SCALE: {VALUE_SCALE} (v_norm = clip(pawns, Â±VALUE_SCALE) / VALUE_SCALE)\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    all_X: List[np.ndarray] = []\n",
    "    all_y_pol: List[np.ndarray] = []\n",
    "    all_y_val: List[float] = []\n",
    "\n",
    "    total_positions = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    # Running stats over normalized values\n",
    "    val_count = 0\n",
    "    val_sum = 0.0\n",
    "    val_sq_sum = 0.0\n",
    "    val_min = float(\"inf\")\n",
    "    val_max = float(\"-inf\")\n",
    "\n",
    "    for i, pgn_path in enumerate(pgn_files):\n",
    "        if max_positions is not None and total_positions >= max_positions:\n",
    "            print(f\"Reached global position cap of {max_positions:,}\")\n",
    "            break\n",
    "\n",
    "        print(f\"ðŸ“ Processing file {i+1}/{len(pgn_files)}: {pgn_path}\")\n",
    "\n",
    "        file_pos_count = 0\n",
    "\n",
    "        try:\n",
    "            iterator = parse_pgn_gz(\n",
    "                filepath=pgn_path,\n",
    "                max_games=max_games_per_file,\n",
    "                min_depth=min_depth,\n",
    "            )\n",
    "\n",
    "            for X, y_pol, y_val_norm in tqdm(iterator, desc=f\"File {i+1}/{len(pgn_files)}\", unit=\"pos\"):\n",
    "                all_X.append(X)\n",
    "                all_y_pol.append(y_pol)\n",
    "                all_y_val.append(y_val_norm)\n",
    "\n",
    "                # Update stats (normalized values in [-1, 1])\n",
    "                val_count += 1\n",
    "                val_sum += y_val_norm\n",
    "                val_sq_sum += y_val_norm * y_val_norm\n",
    "                val_min = min(val_min, y_val_norm)\n",
    "                val_max = max(val_max, y_val_norm)\n",
    "\n",
    "                file_pos_count += 1\n",
    "                total_positions += 1\n",
    "\n",
    "                if len(all_X) >= batch_size:\n",
    "                    save_batch(all_X, all_y_pol, all_y_val, output_dir, batch_count)\n",
    "                    all_X, all_y_pol, all_y_val = [], [], []\n",
    "                    batch_count += 1\n",
    "                    print(\n",
    "                        f\"Saved batch {batch_count-1} | \"\n",
    "                        f\"Running total: {total_positions:,} positions\"\n",
    "                    )\n",
    "\n",
    "                if max_positions is not None and total_positions >= max_positions:\n",
    "                    print(f\"\\n Reached global position cap of {max_positions:,}\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pgn_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Parsed positions from file: {file_pos_count:,}\")\n",
    "        print(f\"Running total: {total_positions:,} positions\")\n",
    "\n",
    "        if file_pos_count == 0:\n",
    "            print(\"WARNING: 0 samples from this file. Likely no eval comments passed the filters.\")\n",
    "\n",
    "        if max_positions is not None and total_positions >= max_positions:\n",
    "            break\n",
    "\n",
    "    # Save remaining\n",
    "    if all_X:\n",
    "        save_batch(all_X, all_y_pol, all_y_val, output_dir, batch_count)\n",
    "        print(f\"Saved final batch {batch_count}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"COMPLETED! Processed {total_positions:,} positions total\")\n",
    "\n",
    "    # Value distribution (normalized)\n",
    "    if val_count > 0:\n",
    "        mean = val_sum / val_count\n",
    "        var = max(val_sq_sum / val_count - mean * mean, 0.0)\n",
    "        std = math.sqrt(var)\n",
    "\n",
    "        print(\"Normalized value distribution (over all emitted positions):\")\n",
    "        print(f\"   Count: {val_count:,}\")\n",
    "        print(f\"   Min:   {val_min:.3f}\")\n",
    "        print(f\"   Max:   {val_max:.3f}\")\n",
    "        print(f\"   Mean:  {mean:.3f}\")\n",
    "        print(f\"   Std:   {std:.3f}\")\n",
    "\n",
    "    # Rough board tensor size estimate\n",
    "    print(f\"Approx board tensor size: ~{(total_positions * 18 * 8 * 8) / (1024**2):.1f} MB\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# USAGE EXAMPLE (script entry point)\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fb132",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "PGN_ROOT   = \"/root/sf_pgns\"                    \n",
    "OUTPUT_DIR = \"./processed_data_playerpov_norm\"  \n",
    "\n",
    "process_all_pgns(\n",
    "    pgn_root=PGN_ROOT,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_positions=5_000_000,   \n",
    "    batch_size=10_000,\n",
    "    max_games_per_file=None,\n",
    "    min_depth=18,\n",
    ")\n",
    "\n",
    "print(\"\\nData ready for training!\")\n",
    "print(\"Output per batch:\")\n",
    "print(\"   X_boards_batch_XXXX.npy : (B, 18, 8, 8)\")\n",
    "print(\"   y_policy_batch_XXXX.npy : (B, 4096)\")\n",
    "print(\"   y_value_batch_XXXX.npy  : (B,)  -- normalized evals in [-1, +1] (POV = side to move)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78091d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
